# algolab_ml/models/train.py
from __future__ import annotations
from typing import Dict, Tuple, Optional
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, f1_score, roc_auc_score, classification_report,
    mean_squared_error, r2_score,
)
from sklearn.utils.class_weight import compute_class_weight

from .model_zoo import get_model
from ..features.transform import build_tabular_preprocess

from pathlib import Path
import inspect

# â€”â€” ç®€å•ä»»åŠ¡è‡ªåŠ¨è¯†åˆ«
def _infer_task(y: pd.Series) -> str:
    nunq = y.nunique(dropna=True)
    if pd.api.types.is_numeric_dtype(y):
        if pd.api.types.is_float_dtype(y):
            as_int = (y.dropna().round() == y.dropna()).mean()
            if as_int > 0.98 and nunq <= max(20, int(len(y)*0.05)):
                return "classification"
        if nunq <= max(20, int(len(y)*0.01)):
            return "classification"
        return "regression"
    else:
        return "classification"

# â€”â€” é»˜è®¤æœç´¢ç©ºé—´ï¼ˆå¯é€‰ï¼‰
_DEFAULT_PARAM_GRID = {
    "lgbm": {
        "model__n_estimators": [100, 200, 400],
        "model__learning_rate": [0.05, 0.1],
        "model__num_leaves": [31, 63, 127],
        "model__subsample": [0.8, 1.0],
        "model__colsample_bytree": [0.8, 1.0],
    },
    "xgb": {
        "model__n_estimators": [200, 400],
        "model__learning_rate": [0.05, 0.1],
        "model__max_depth": [3, 5, 7],
        "model__subsample": [0.8, 1.0],
        "model__colsample_bytree": [0.8, 1.0],
    },
    "rf": {
        "model__n_estimators": [200, 400],
        "model__max_depth": [None, 10, 20],
        "model__max_features": ["sqrt", "log2", None],
    },
}

def build_pipeline(pre, model):
    # æ³¨æ„ï¼šæœ€ç»ˆå¯¼å‡ºä»ç„¶ç”¨ sklearn.Pipeline åŒ…è£¹ï¼ˆå“ªæ€•æˆ‘ä»¬åœ¨å†…éƒ¨ç”¨çŸ©é˜µæ‹Ÿåˆï¼‰
    from sklearn.pipeline import Pipeline
    return Pipeline([("preprocess", pre), ("model", model)])


def _build_preprocessor(df_with_target: pd.DataFrame, target: str, enable: bool):
    """
    å…¼å®¹ä¸åŒç‰ˆæœ¬çš„ build_tabular_preprocess ç­¾åï¼Œå¹¶ä¸”
    â€”â€”å…³é”®ä¿®å¤ï¼šç”¨ä¸å« target åˆ—çš„ X æ¥æž„å»ºé¢„å¤„ç†å™¨ï¼Œé¿å…åœ¨ CV/Pipeline ä¸­å¼•ç”¨ 'label'ã€‚
    """
    from ..features.transform import build_tabular_preprocess  # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªçŽ¯

    # ðŸš‘ å…³é”®ï¼šå‰”é™¤ target åˆ—åŽå†äº¤ç»™æž„å»ºå‡½æ•°
    dfX = df_with_target.drop(columns=[target], errors="ignore")

    try:
        sig = inspect.signature(build_tabular_preprocess)
        params = sig.parameters
        if "target" in params:
            # ä¼  target ä»…ç”¨äºŽä¸€äº›å‡½æ•°å†…éƒ¨éœ€è¦ï¼Œä½†çœŸæ­£ç”¨äºŽåˆ—æŽ¨æ–­çš„æ˜¯ dfXï¼ˆæ—  targetï¼‰
            return build_tabular_preprocess(dfX, target=target, enable=enable)
        if "target_col" in params:
            return build_tabular_preprocess(dfX, target_col=target, enable=enable)
        try:
            return build_tabular_preprocess(dfX, enable=enable)
        except TypeError:
            return build_tabular_preprocess(dfX)
    except Exception:
        try:
            return build_tabular_preprocess(dfX, target_col=target, enable=enable)
        except TypeError:
            return build_tabular_preprocess(dfX)


def _maybe_set_class_weight_param(model, class_weight: str):
    """
    è‹¥åº•å±‚ä¼°è®¡å™¨æ”¯æŒ class_weightï¼Œåˆ™ç›´æŽ¥è®¾ç½®ï¼›å¦åˆ™å¿½ç•¥ã€‚
    """
    if not class_weight or class_weight == "none":
        return
    try:
        params = model.get_params(deep=True)
        if "class_weight" in params:
            model.set_params(class_weight=class_weight)
    except Exception:
        pass


def _compute_sample_weights(y: pd.Series,
                            sample_weight_col_values: Optional[pd.Series],
                            class_weight: str) -> Optional[np.ndarray]:
    """
    åˆæˆæœ€ç»ˆ sample_weight:
    - è‹¥ class_weight = balanced / balanced_subsampleï¼šæŒ‰é¢‘æ¬¡è®¡ç®—æ¯ç±»æƒé‡ï¼ˆå¤šåˆ†ç±»ä¹Ÿæ”¯æŒï¼‰
    - ä¸Ž sample_weight_colï¼ˆè‹¥æä¾›ï¼‰ç›¸ä¹˜
    """
    w = None
    if class_weight and class_weight != "none":
        classes = np.unique(y)
        try:
            cw = compute_class_weight(class_weight="balanced", classes=classes, y=y)
            cw_map = {cls: weight for cls, weight in zip(classes, cw)}
            w = y.map(cw_map).astype("float64").values
        except Exception:
            w = None

    if sample_weight_col_values is not None:
        sw = pd.to_numeric(sample_weight_col_values, errors="coerce").fillna(0.0).values
        if w is None:
            w = sw
        else:
            w = w * sw

    return w


def fit_tabular(
    df: pd.DataFrame,
    target: str,
    model_name: str,
    test_size: float = 0.2,
    random_state: int = 42,
    preprocess: bool = True,
    model_params: Dict | None = None,
    task_override: Optional[str] = None,
    cv: int = 0,
    search: str = "grid",
    n_iter: int = 20,
    scoring: Optional[str] = None,
    param_grid: Optional[str] = None,
    early_stopping: bool = False,
    val_size: float = 0.15,
    es_rounds: int = 50,
    eval_metric: Optional[str] = None,
    # ç¬¬6æ­¥æ–°å¢ž
    sample_weight_col: Optional[str] = None,
    class_weight: str = "none",            # none|balanced|balanced_subsample
    smote: bool = False,
) -> Tuple[object, dict]:

    import warnings
    model_params = model_params or {}
    y = df[target]
    X = df.drop(columns=[target])

    task = task_override or _infer_task(y)
    report: Dict = {"task": task}

    # åˆæˆæ ·æœ¬æƒé‡ï¼ˆå…ˆä¸è€ƒè™‘ SMOTEï¼›SMOTE æ—¶å¦è¡Œå¤„ç†ï¼‰
    sample_weight_series = None
    if sample_weight_col and sample_weight_col in df.columns:
        sample_weight_series = df[sample_weight_col]
        report["sample_weight_col"] = sample_weight_col

    # â€”â€” åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•
    Xtr, Xte, ytr, yte = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=None if task == "regression" else y
    )

    # è®­ç»ƒé˜¶æ®µå…ˆæ‹Ÿåˆé¢„å¤„ç†å™¨
    pre = _build_preprocessor(pd.concat([Xtr, ytr], axis=1), target=target, enable=preprocess)

    # æž„å»ºæ¨¡åž‹å¹¶å°½é‡è®¾ç½® class_weightï¼ˆè‹¥æ¨¡åž‹æ”¯æŒï¼‰
    model = get_model(model_name, task, **model_params)
    _maybe_set_class_weight_param(model, class_weight)

    # è®¡ç®—è®­ç»ƒé›†æ ·æœ¬æƒé‡ï¼ˆåœ¨åŽç»­åˆ†æ”¯é‡Œåˆ‡å­é›†/é‡é‡‡æ ·ï¼‰
    base_weight = _compute_sample_weights(
        ytr,
        sample_weight_series.loc[ytr.index] if sample_weight_series is not None else None,
        class_weight=class_weight,
    )
    if base_weight is not None:
        report["weights_stats"] = {
            "n_nonnull": int(np.isfinite(base_weight).sum()),
            "min": float(np.nanmin(base_weight)),
            "max": float(np.nanmax(base_weight)),
            "mean": float(np.nanmean(base_weight)),
            "sum": float(np.nansum(base_weight)),
        }

    # ============ CV æœç´¢ ============
    if isinstance(cv, int) and cv >= 2:
        from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
        from sklearn.pipeline import Pipeline
        pipe = Pipeline([("preprocess", pre), ("model", model)])

        # SMOTE ä¸Ž CVï¼šå½“å‰ç‰ˆæœ¬è·³è¿‡ï¼ˆé¿å…æƒé‡ä¸Žæ ·æœ¬æ•°ä¸ä¸€è‡´çš„å¤æ‚æ€§ï¼‰
        if smote:
            warnings.warn("å·²å¯ç”¨ CVï¼šå½“å‰ç‰ˆæœ¬åœ¨ CV ä¸­ä¸åº”ç”¨ SMOTEï¼ˆå°†ç»§ç»­æ—  SMOTE è¿›è¡Œæœç´¢ï¼‰ã€‚")

        # æœç´¢ç©ºé—´
        if param_grid and isinstance(param_grid, str) and param_grid.strip().startswith("@"):
            import json
            pg = json.loads(Path(param_grid[1:]).read_text(encoding="utf-8"))
        elif param_grid and isinstance(param_grid, str):
            import json
            pg = json.loads(param_grid)
        else:
            pg = _DEFAULT_PARAM_GRID.get(model_name, {})

        if search == "random":
            searcher = RandomizedSearchCV(
                pipe, pg, n_iter=n_iter, scoring=scoring, cv=cv, n_jobs=None, refit=True, random_state=random_state
            )
        else:
            searcher = GridSearchCV(
                pipe, pg, scoring=scoring, cv=cv, n_jobs=None, refit=True
            )

        fit_kwargs = {}
        if base_weight is not None:
            # Pipeline ä¸‹éœ€ç”¨ step å‰ç¼€
            fit_kwargs["model__sample_weight"] = base_weight

        searcher.fit(Xtr, ytr, **fit_kwargs)
        best_pipe = searcher.best_estimator_
        yhat = best_pipe.predict(Xte)

        if task == "classification":
            # å°è¯•æ¦‚çŽ‡
            yprob = None
            try:
                yproba = best_pipe.predict_proba(Xte)
                if yproba.ndim == 2 and yproba.shape[1] >= 2:
                    yprob = yproba[:, 1]
                else:
                    yprob = yproba
            except Exception:
                pass
            acc = float(accuracy_score(yte, yhat))
            f1m = float(f1_score(yte, yhat, average="macro"))
            report.update({"accuracy": acc, "f1_macro": f1m})
            if yprob is not None and len(np.unique(yte)) == 2:
                report["roc_auc"] = float(roc_auc_score(yte, yprob))
            report["classification_report"] = classification_report(yte, yhat, output_dict=True)
            report["_y_true"], report["_y_pred"] = yte.tolist(), yhat.tolist()
            report["_y_prob"] = (yprob.tolist() if yprob is not None else None)
        else:
            rmse = float(mean_squared_error(yte, yhat, squared=False))
            r2 = float(r2_score(yte, yhat))
            report.update({"rmse": rmse, "r2": r2})

        # å°†å¸¦ cv_results_ çš„å¯¹è±¡è¿”å›žï¼Œä¾› save_cv_results ä½¿ç”¨
        return best_pipe, {**report, "cv": True, "best_params": getattr(searcher, "best_params_", None),
                           "best_score": getattr(searcher, "best_score_", None)}

    # ============ æ—©åœåˆ†æ”¯ï¼ˆlgbm / xgb / catboostï¼‰ ============
    if early_stopping and model_name in ("lgbm", "xgb", "catboost"):
        from sklearn.exceptions import NotFittedError

        Xtr2, Xval, ytr2, yval = train_test_split(
            Xtr, ytr, test_size=val_size, random_state=random_state, stratify=None if task == "regression" else ytr
        )
        # æ‹Ÿåˆé¢„å¤„ç†å™¨
        Xtr2_t = pre.fit_transform(pd.concat([Xtr2, ytr2], axis=1), ytr2) if preprocess else Xtr2.values
        Xval_t = pre.transform(pd.concat([Xval, yval], axis=1)) if preprocess else Xval.values
        Xte_t  = pre.transform(pd.concat([Xte,  yte],  axis=1)) if preprocess else Xte.values

        # è®­ç»ƒå­é›†çš„æ ·æœ¬æƒé‡
        w_tr2 = None
        if base_weight is not None:
            w_tr2 = base_weight[ytr2.index] if isinstance(base_weight, pd.Series) else base_weight
            # æ³¨æ„ï¼šä¸Šä¸€æ­¥ base_weight å·²æ˜¯ ndarrayï¼›è¿™é‡Œç›´æŽ¥æ ¹æ® ytr2 çš„ä½ç½®åˆ‡ä¸æ–¹ä¾¿
            # ç®€åŒ–å¤„ç†ï¼šé‡ç®—ä¸€éæ›´ç¨³å¦¥
            w_tr2 = _compute_sample_weights(
                ytr2,
                sample_weight_series.loc[ytr2.index] if sample_weight_series is not None else None,
                class_weight=class_weight,
            )

        # SMOTEï¼ˆä»…å¯¹è®­ç»ƒå­é›†ï¼‰
        if smote and task == "classification":
            try:
                from imblearn.over_sampling import SMOTE
                sm = SMOTE(random_state=random_state)
                Xtr2_t, ytr2 = sm.fit_resample(Xtr2_t, ytr2)
                if w_tr2 is not None:
                    # æ—©åœè·¯å¾„ä¸‹æ— æ³•å®‰å…¨å¯¹é½æƒé‡ä¸Ž SMOTE çš„åˆæˆæ ·æœ¬ï¼Œå¿½ç•¥æƒé‡å¹¶æç¤º
                    print("âš ï¸  å·²å¯ç”¨ SMOTEï¼ˆæ—©åœåˆ†æ”¯ï¼‰ï¼šè®­ç»ƒæ ·æœ¬æƒé‡å°†è¢«å¿½ç•¥ã€‚")
                w_tr2 = None
            except Exception as e:
                print(f"âš ï¸  SMOTE å¤±è´¥ï¼ˆå·²è·³è¿‡ï¼‰ï¼š{e}")

        # é€‚é…æ—©åœå‚æ•°
        fit_kwargs = {}
        if model_name == "lgbm":
            import lightgbm as lgb
            fit_kwargs["eval_set"] = [(Xval_t, yval)]
            if eval_metric: fit_kwargs["eval_metric"] = eval_metric
            fit_kwargs["callbacks"] = [lgb.early_stopping(es_rounds, verbose=False)]
        elif model_name == "xgb":
            fit_kwargs["eval_set"] = [(Xval_t, yval)]
            if eval_metric: fit_kwargs["eval_metric"] = eval_metric
            fit_kwargs["early_stopping_rounds"] = es_rounds
            if hasattr(model, "get_xgb_params"):
                if "verbose" not in model.get_xgb_params():
                    fit_kwargs["verbose"] = False
        elif model_name == "catboost":
            # CatBoost: eval_set=(X_val,y_val) & verbose
            fit_kwargs["eval_set"] = (Xval_t, yval)
            if eval_metric:
                fit_kwargs["eval_metric"] = eval_metric
            fit_kwargs["verbose"] = False

        # æ‹Ÿåˆ
        clf = model
        try:
            clf.fit(Xtr2_t, ytr2, sample_weight=w_tr2, **fit_kwargs)
        except TypeError:
            # æŸäº›æ¨¡åž‹ä¸æŽ¥å— sample_weight
            clf.fit(Xtr2_t, ytr2, **fit_kwargs)

        # æŽ¨ç†
        yhat = clf.predict(Xte_t)
        yprob = None
        if task == "classification":
            try:
                proba = clf.predict_proba(Xte_t)
                if proba.ndim == 2 and proba.shape[1] >= 2:
                    yprob = proba[:, 1]
                else:
                    yprob = proba
            except Exception:
                pass

        # è¯„ä¼°
        if task == "classification":
            acc = float(accuracy_score(yte, yhat))
            f1m = float(f1_score(yte, yhat, average="macro"))
            report.update({"accuracy": acc, "f1_macro": f1m})
            if yprob is not None and len(np.unique(yte)) == 2:
                report["roc_auc"] = float(roc_auc_score(yte, yprob))
            report["classification_report"] = classification_report(yte, yhat, output_dict=True)
            report["_y_true"], report["_y_pred"] = yte.tolist(), yhat.tolist()
            report["_y_prob"] = (yprob.tolist() if yprob is not None else None)
        else:
            rmse = float(mean_squared_error(yte, yhat, squared=False))
            r2 = float(r2_score(yte, yhat))
            report.update({"rmse": rmse, "r2": r2})

        if hasattr(clf, "best_iteration_"):
            report["best_iteration"] = int(clf.best_iteration_)
        ev = None
        if hasattr(clf, "evals_result_"):
            ev = clf.evals_result_
        elif hasattr(clf, "evals_result"):
            try:
                ev = clf.evals_result()
            except Exception:
                ev = None
        if ev:
            report["evals_result"] = ev

        pipe = build_pipeline(pre, clf)
        return pipe, report

    # ============ æ™®é€šè®­ç»ƒï¼ˆæ— æ—©åœ/æ—  CVï¼‰ ============
    # ç»Ÿä¸€èµ°â€œé¢„å¤„ç†â†’ï¼ˆå¯é€‰ SMOTEï¼‰â†’ æ‹Ÿåˆåº•æ¨¡â€çš„è·¯å¾„ï¼Œç¡®ä¿æƒé‡/SMOTE éƒ½ç¨³å®šå¯æŽ§
    Xtr_t = pre.fit_transform(pd.concat([Xtr, ytr], axis=1), ytr) if preprocess else Xtr.values
    Xte_t = pre.transform(pd.concat([Xte, yte], axis=1)) if preprocess else Xte.values

    w_tr = base_weight
    if smote and task == "classification":
        try:
            from imblearn.over_sampling import SMOTE
            sm = SMOTE(random_state=random_state)
            Xtr_t, ytr = sm.fit_resample(Xtr_t, ytr)
            if w_tr is not None:
                print("âš ï¸  å·²å¯ç”¨ SMOTEï¼šè®­ç»ƒæ ·æœ¬æƒé‡å°†è¢«å¿½ç•¥ï¼ˆé•¿åº¦æ— æ³•ä¸Žåˆæˆæ ·æœ¬å¯¹é½ï¼‰ã€‚")
            w_tr = None
        except Exception as e:
            print(f"âš ï¸  SMOTE å¤±è´¥ï¼ˆå·²è·³è¿‡ï¼‰ï¼š{e}")

    clf = model
    try:
        clf.fit(Xtr_t, ytr, sample_weight=w_tr)
    except TypeError:
        clf.fit(Xtr_t, ytr)

    # æŽ¨ç†
    yhat = clf.predict(Xte_t)

    if task == "classification":
        yprob = None
        try:
            proba = clf.predict_proba(Xte_t)
            if proba.ndim == 2 and proba.shape[1] >= 2:
                yprob = proba[:, 1]
            else:
                yprob = proba
        except Exception:
            pass
        acc = float(accuracy_score(yte, yhat))
        f1m = float(f1_score(yte, yhat, average="macro"))
        report.update({"accuracy": acc, "f1_macro": f1m})
        if yprob is not None and len(np.unique(yte)) == 2:
            report["roc_auc"] = float(roc_auc_score(yte, yprob))
        report["classification_report"] = classification_report(yte, yhat, output_dict=True)
        report["_y_true"], report["_y_pred"] = yte.tolist(), yhat.tolist()
        report["_y_prob"] = (yprob.tolist() if yprob is not None else None)
    else:
        rmse = float(mean_squared_error(yte, yhat, squared=False))
        r2 = float(r2_score(yte, yhat))
        report.update({"rmse": rmse, "r2": r2})

    pipe = build_pipeline(pre, clf)
    return pipe, report
